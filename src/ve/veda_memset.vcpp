#include "veda_device_internal.h"
#include <type_traits>

typedef struct { uint64_t x; uint64_t y; } uint128_t;

#define VLEN 256
constexpr size_t D8_HEURISTIC	= (2 * 1024 * 1024);
constexpr size_t D64_HEURISTIC	= (2 * 1024 * 1024);
constexpr size_t D128_HEURISTIC	= (1 * 1024 * 1024);

//------------------------------------------------------------------------------
template<typename T>
static inline void vedaMemsetAlign(T*& ptr, const T value, size_t& cnt) {
	// If there ptr % size == 0, everything is aligned
	if(auto byteOffset = ((size_t)ptr) % sizeof(uint64_t)) {
		/**
		 * Explanaition:
		 * ptr = ***XXXXX --> alignCnt == 3
		 * so we need to fill up 8-3 = 5 elements
		 */
		auto alignCnt = (sizeof(uint64_t) - byteOffset) / sizeof(T);
		for(size_t i = 0; i < alignCnt; i++)
			ptr[i] = value;
		ptr += alignCnt;
		cnt -= alignCnt;
	}
}

//------------------------------------------------------------------------------
template<typename T>
static inline void vedaMemsetOMPBatched(T*& ptr, const T value, size_t& cnt) {
	static_assert(sizeof(T) > 1 && sizeof(T) < 8);
	const T raw[]	= {value, value, value, value};
	auto batchValue	= ((const uint64_t*)raw)[0];

	auto batchSize	= sizeof(uint64_t) / sizeof(T);
	auto batchCnt	= cnt / batchSize;

	vedaMemsetD64(ptr, batchValue, batchCnt);

	ptr += batchCnt * batchSize;
	cnt -= batchCnt * batchSize;
}

//------------------------------------------------------------------------------
template<typename T>
static inline void vedaMemsetBatched(T*& ptr, const T value, size_t& cnt) {
	static_assert(sizeof(T) > 1 && sizeof(T) < 8);
	T raw[]		= {value, value, value, value};
	auto batchValue	= ((const uint64_t*)raw)[0];

	auto batchSize	= sizeof(uint64_t) / sizeof(T);
	auto batchCnt	= cnt / batchSize;

	auto uptr = (uint64_t*)ptr;
	#pragma _NEC vector
	for(size_t i = 0; i < batchCnt; i++)
		uptr[i] = batchValue;

	ptr += batchCnt * batchSize;
	cnt -= batchCnt * batchSize;
}

//------------------------------------------------------------------------------
template<typename T>
static inline void vedaMemsetRemaining(T*& ptr, const T value, size_t& cnt) {
	for(size_t i = 0; i < cnt; i++)
		ptr[i] = value;
}

//------------------------------------------------------------------------------
template<typename T>
static inline void vedaMemsetDX(T* ptr, const T value, size_t cnt) {
	vedaMemsetAlign		(ptr, value, cnt);
	vedaMemsetOMPBatched	(ptr, value, cnt);
	vedaMemsetRemaining	(ptr, value, cnt);
}

//------------------------------------------------------------------------------
template<typename T>
static inline void vedaMemsetD2DX(T* _ptr, const size_t pitch, const T value, const size_t w, const size_t h) {
	veda_omp(h, [&](const size_t min, const size_t max) {
		#pragma _NEC novector
		for(size_t h = min; h < max; h++) {
			auto ptr = _ptr + (h * pitch);
			auto cnt = w;
			vedaMemsetAlign		(ptr, value, cnt);
			vedaMemsetBatched	(ptr, value, cnt);
			vedaMemsetRemaining	(ptr, value, cnt);
		}
	});
}

//------------------------------------------------------------------------------
extern "C" {
//------------------------------------------------------------------------------
// 1D MemSet
//------------------------------------------------------------------------------
VEDAresult vedaMemsetD8(void* ptr, const uint8_t  value, const size_t cnt) {
	if(cnt > D8_HEURISTIC) {
		veda_omp_simd(cnt, [&](const size_t min, const size_t max) {
			memset(((uint8_t*)ptr)+min, value, max-min);
		});
	} else {
		memset(ptr, value, cnt);
	}
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD16(void* ptr, const uint16_t value, const size_t cnt) {
	vedaMemsetDX((uint16_t*)ptr, value, cnt);
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD32(void* ptr, const uint32_t value, const size_t cnt) {
	vedaMemsetDX((uint32_t*)ptr, value, cnt);
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD64(void* _ptr, const uint64_t value, const size_t _cnt) {
	if(_cnt >= D64_HEURISTIC) {
		veda_omp_simd(_cnt, [=](const size_t min, const size_t max) {
			auto ptr = ((uint64_t*)_ptr) + min;
			auto cnt = max - min;

			#pragma _NEC vector
			for(size_t i = 0; i < cnt; i++)
				ptr[i] = value;
		}, size_t(256));
	} else {
		auto ptr = (uint64_t*)_ptr;
		#pragma _NEC vector
		for(size_t i = 0; i < _cnt; i++)
			ptr[i] = value;
	}
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD128(void* _ptr, const uint64_t x, const uint64_t y, const size_t _cnt) {
	if(_cnt >= D128_HEURISTIC) {
		veda_omp_simd(_cnt, [=](const size_t min, const size_t max) {
			auto ptr = ((uint128_t*)_ptr) + min;
			auto cnt = max - min;
			#pragma _NEC vector
			for(size_t i = 0; i < cnt; i++) {
				ptr[i].x = x;
				ptr[i].y = y;
			}
		}, size_t(256));
	} else {
		auto ptr = (uint128_t*)_ptr;
		#pragma _NEC vector
		for(size_t i = 0; i < _cnt; i++) {
			ptr[i].x = x;
			ptr[i].y = y;
		}
	}
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
// 2D MemSet
//------------------------------------------------------------------------------
VEDAresult vedaMemsetD2D8(void* _ptr, const size_t pitch, const uint8_t value, const size_t w, const size_t h)	{
	veda_omp(h, [&](const size_t min, const size_t max) {
		#pragma _NEC novector
		for(size_t h = min; h < max; h++) {
			auto ptr = ((uint8_t*)_ptr) + (h * pitch);
			memset(ptr, value, w);
		}
	});
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD2D16(void* ptr, const size_t pitch, const uint16_t value, const size_t w, const size_t h)	{
	vedaMemsetD2DX((uint16_t*)ptr, pitch, value, w, h);
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD2D32(void* ptr, const size_t pitch, const uint32_t value, const size_t w, const size_t h)	{
	vedaMemsetD2DX((uint32_t*)ptr, pitch, value, w, h);
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD2D64(void* _ptr, const size_t pitch, const uint64_t value, const size_t w, const size_t h) {
	veda_omp(h, [=](const size_t min, const size_t max) {
		#pragma _NEC novector
		for(size_t h = min; h < max; h++) {
			auto ptr = ((uint64_t*)_ptr) + (h * pitch);
			#pragma _NEC vector
			for(size_t i = 0; i < w; i++)
				ptr[i] = value;
		}
	});
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD2D128(void* _ptr, const size_t pitch, const uint64_t x, const uint64_t y, const size_t w, const size_t h) {
	veda_omp(h, [=](const size_t min, const size_t max) {
		#pragma _NEC novector
		for(size_t h = min; h < max; h++) {
			auto ptr = ((uint128_t*)_ptr) + (h * pitch);
			#pragma _NEC vector
			for(size_t i = 0; i < w; i++) {
				ptr[i].x = x;
				ptr[i].y = y;
			}
		}
	});
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
}
