#include "internal.h"
#include <type_traits>

typedef struct { uint64_t x; uint64_t y; } uint128_t;

#define VLEN 256
#define MODE 2 // NAIVE == 0, VECTOR == 1, OMP == 2

constexpr size_t MEMSET_HEURISTIC = MODE == 2 ? (2 * 1024 * 1024) : size_t(-1);
constexpr size_t MEMCPY_HEURISTIC = MODE == 2 ? (2 * 1024 * 1024) : size_t(-1);

//------------------------------------------------------------------------------
template<typename T>
static inline void memset_sequential(T* dst, const T value, const size_t cnt) {
	#pragma _NEC novector
	for(size_t i = 0; i < cnt; i++)
		dst[i] = value;
}

//------------------------------------------------------------------------------
template<typename T>
static inline void memset_vectorized(T* dst, const T value, const size_t cnt) {
	#pragma _NEC select_vector
	for(size_t i = 0; i < cnt; i++)
		dst[i] = value;
}

//------------------------------------------------------------------------------
template<typename T>
static inline void vedaMemsetDX(T* dst, const T value, size_t cnt) {
	static_assert(sizeof(T) > 1 && sizeof(T) < 8);

#if MODE == 0
	memset_vectorized(dst, value, cnt);
#else
	auto byte_offset = ((size_t)dst) % sizeof(int64_t);
	
	// set values sequentially until ptr is aligned
	auto alignment_cnt = std::min((sizeof(int64_t) - byte_offset) / sizeof(T), cnt);
	if(alignment_cnt) {
		memset_sequential<T>(dst, value, alignment_cnt);
		dst += alignment_cnt;
		cnt -= alignment_cnt;
	}
	
	// set values vectorized using 64-bit dtype
	if(cnt) {
		auto items_per_iteration		= sizeof(int64_t) / sizeof(T);
		auto vector_cnt				= cnt / items_per_iteration;
		if(vector_cnt) {
			const T vx[]			= {value, value, value, value};
			const int64_t v64		= *(const int64_t*)&vx;
			if((vector_cnt * sizeof(uint64_t)) >= MEMSET_HEURISTIC) {
				veda_omp_simd(vector_cnt, [&](const size_t min, const size_t max) {
					memset_vectorized(((int64_t*)dst) + min, v64, max-min);
				});
			} else {
				memset_vectorized((int64_t*)dst, v64, vector_cnt);
			}
			
			dst += vector_cnt * items_per_iteration;
			cnt -= vector_cnt * items_per_iteration;
		}
	}

	// set remaining items sequentially
	if(cnt) {
		memset_sequential<T>(dst, value, cnt);
	}
#endif
}

//------------------------------------------------------------------------------
template<typename T>
static inline void vedaMemsetD2DX(T* _ptr, const size_t pitch, const T value, const size_t w, const size_t h) {
	veda_omp(h, [&](const size_t min, const size_t max) {
		#pragma _NEC novector
		for(size_t h = min; h < max; h++) {
			auto ptr = _ptr + (h * pitch / sizeof(T));
			vedaMemsetDX(ptr, value, w);
		}
	});
}

//------------------------------------------------------------------------------
extern "C" {
//------------------------------------------------------------------------------
// 1D MemSet
//------------------------------------------------------------------------------
VEDAresult vedaMemsetD8(void* ptr, const uint8_t value, const size_t cnt) {
#if MODE == 0
	memset(ptr, value, cnt);
#else
	if((cnt * sizeof(uint8_t)) >= MEMSET_HEURISTIC) {
		veda_omp_simd(cnt, [&](const size_t min, const size_t max) {
			memset(((uint8_t*)ptr)+min, value, max-min);
		});
	} else {
		memset(ptr, value, cnt);
	}
#endif
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD16(void* ptr, const uint16_t value, const size_t cnt) {
	vedaMemsetDX((uint16_t*)ptr, value, cnt);
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD32(void* ptr, const uint32_t value, const size_t cnt) {
	vedaMemsetDX((uint32_t*)ptr, value, cnt);
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD64(void* _ptr, const uint64_t value, const size_t _cnt) {
#if MODE == 0
	memset_vectorized((uint64_t*)_ptr, value, _cnt);
#else
	if((_cnt * sizeof(uint64_t)) >= MEMSET_HEURISTIC) {
		veda_omp_simd(_cnt, [=](const size_t min, const size_t max) {
			auto ptr = ((uint64_t*)_ptr) + min;
			auto cnt = max - min;

			#pragma _NEC vector
			for(size_t i = 0; i < cnt; i++)
				ptr[i] = value;
		}, size_t(256));
	} else {
		memset_vectorized((uint64_t*)_ptr, value, _cnt);
	}
#endif
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD128(void* _ptr, const uint64_t x, const uint64_t y, const size_t _cnt) {
#if MODE == 0
	auto ptr = (uint128_t*)_ptr;
	#pragma _NEC select_vector
	for(size_t i = 0; i < _cnt; i++) {
		ptr[i].x = x;
		ptr[i].y = y;
	}
#else
	if((_cnt * sizeof(uint128_t)) >= MEMSET_HEURISTIC) {
		veda_omp_simd(_cnt, [=](const size_t min, const size_t max) {
			auto ptr = ((uint128_t*)_ptr) + min;
			auto cnt = max - min;
			#pragma _NEC vector
			for(size_t i = 0; i < cnt; i++) {
				ptr[i].x = x;
				ptr[i].y = y;
			}
		}, size_t(256));
	} else {
		auto ptr = (uint128_t*)_ptr;
		#pragma _NEC vector
		for(size_t i = 0; i < _cnt; i++) {
			ptr[i].x = x;
			ptr[i].y = y;
		}
	}
#endif
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
// 2D MemSet
//------------------------------------------------------------------------------
VEDAresult vedaMemsetD2D8(void* _ptr, const size_t pitch, const uint8_t value, const size_t w, const size_t h)	{
	veda_omp(h, [&](const size_t min, const size_t max) {
		#pragma _NEC novector
		for(size_t h = min; h < max; h++) {
			auto ptr = ((uint8_t*)_ptr) + (h * pitch);
			memset(ptr, value, w);
		}
	});
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD2D16(void* ptr, const size_t pitch, const uint16_t value, const size_t w, const size_t h)	{
	vedaMemsetD2DX((uint16_t*)ptr, pitch, value, w, h);
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD2D32(void* ptr, const size_t pitch, const uint32_t value, const size_t w, const size_t h)	{
	vedaMemsetD2DX((uint32_t*)ptr, pitch, value, w, h);
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD2D64(void* _ptr, const size_t pitch, const uint64_t value, const size_t w, const size_t h) {
	veda_omp(h, [=](const size_t min, const size_t max) {
		#pragma _NEC novector
		for(size_t h = min; h < max; h++) {
			auto ptr = ((uint64_t*)_ptr) + (h * pitch);
			#pragma _NEC vector
			for(size_t i = 0; i < w; i++)
				ptr[i] = value;
		}
	});
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemsetD2D128(void* _ptr, const size_t pitch, const uint64_t x, const uint64_t y, const size_t w, const size_t h) {
	veda_omp(h, [=](const size_t min, const size_t max) {
		#pragma _NEC novector
		for(size_t h = min; h < max; h++) {
			auto ptr = ((uint128_t*)_ptr) + (h * pitch);
			#pragma _NEC vector
			for(size_t i = 0; i < w; i++) {
				ptr[i].x = x;
				ptr[i].y = y;
			}
		}
	});
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
VEDAresult vedaMemcpy(void* dst_, const void* src_, const size_t bytes) {
	if(bytes >= MEMCPY_HEURISTIC) {
		veda_omp_simd(bytes, [=](const size_t min, const size_t max) {
			memcpy(((char*)dst_) + min, ((char*)src_) + min, max - min);
		}, 256 * sizeof(uint64_t));
	} else {
		memcpy(dst_, src_, bytes);
	}
	return VEDA_SUCCESS;
}

//------------------------------------------------------------------------------
}
